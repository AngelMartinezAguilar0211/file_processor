defmodule FileProcessor.ReportGenerator do
  # Builds the complete report content as a single string.
  # Receives a fully-structured report_data map generated by FileProcessor.
  def build(report_data) do
    # Capture the current UTC timestamp truncated to seconds
    now = NaiveDateTime.utc_now() |> NaiveDateTime.truncate(:second)

    # Build the report header section
    header = """
    ================================================================================
                        REPORTE DE PROCESAMIENTO DE ARCHIVOS
    ================================================================================
    Fecha de generación: #{now}
    Directorio único: #{report_data.directory || "N/A"}
    Modo de procesamiento: #{report_data.mode}
    """

    # Build each major section of the report independently
    summary = build_summary(report_data)
    csv_section = build_csv(report_data.csv_files, report_data.csv_totals)
    json_section = build_json(report_data.json_files, report_data.json_totals)
    log_section = build_log(report_data.log_files, report_data.log_totals)
    errors_section = build_errors(report_data.errors)

    # Concatenate all sections into a single string
    [header, summary, csv_section, json_section, log_section, errors_section, footer()]
    |> Enum.join("\n")
  end

  # Writes the report content to disk and returns the absolute path.
  # Raises an exception if the write fails (intentional, fail-fast behavior).
  def write!(path, content) do
    File.write!(path, content)
    Path.expand(path)
  end

  # Builds the executive summary section of the report.
  defp build_summary(d) do
    # Extract basic counters
    total = d.counts.total
    ok = d.counts.ok
    failed = d.counts.failed

    # Avoid division by zero
    success_rate =
      if total == 0 do
        0.0
      else
        ok * 100.0 / total
      end

    """
    --------------------------------------------------------------------------------
    RESUMEN EJECUTIVO
    --------------------------------------------------------------------------------
    Total de archivos procesados: #{total}
      - Archivos CSV: #{d.counts.csv}
      - Archivos JSON: #{d.counts.json}
      - Archivos LOG: #{d.counts.log}

    Tiempo total de procesamiento: #{format_seconds(d.elapsed_seconds)} segundos
    Archivos con errores: #{failed}
    Tasa de éxito: #{Float.round(success_rate, 1)}%
    """
  end

  # Builds the CSV metrics section, including per-file metrics
  # and consolidated totals.
  defp build_csv(files, totals) do
    # Generate a formatted block per CSV file
    per_file =
      files
      |> Enum.map(fn f ->
        """
        [Archivo: #{Path.basename(f.path)}]
          * Total de ventas: $#{Float.round(f.metrics.total_sales, 2)}
          * Productos únicos: #{f.metrics.unique_products}
          * Producto más vendido: #{format_top(f.metrics.top_product, "unidades")}
          * Categoría con mayor ingreso: #{format_top_money(f.metrics.top_category)}
          * Promedio de descuento aplicado: #{Float.round(f.metrics.avg_discount_pct, 2)}%
          * Período: #{format_range(f.metrics.date_range)}
        """
      end)
      |> Enum.join("\n")

    # Consolidated totals across all CSV files
    totals_text =
      """
      Totales Consolidados CSV:
        - Ventas totales: $#{Float.round(totals.total_sales, 2)}
        - Productos únicos totales: #{totals.unique_products}
      """

    """
    --------------------------------------------------------------------------------
    MÉTRICAS DE ARCHIVOS CSV
    --------------------------------------------------------------------------------
    #{if per_file == "", do: "No CSV files processed.\n", else: per_file}
    #{totals_text}
    """
  end

  # Builds the JSON metrics section, including per-file metrics
  # and consolidated totals.
  defp build_json(files, totals) do
    per_file =
      files
      |> Enum.map(fn f ->
        """
        [Archivo: #{Path.basename(f.path)}]
          * Usuarios registrados: #{f.metrics.total_users}
          * Usuarios activos: #{f.metrics.active_users}
          * Usuarios inactivos: #{f.metrics.inactive_users}
          * Duración promedio de sesión: #{Float.round(f.metrics.avg_session_seconds / 60.0, 2)} minutos
          * Páginas visitadas totales: #{f.metrics.total_pages}
          * Top acciones:
        #{format_actions(f.metrics.top_actions)}
          * Hora pico de actividad: #{format_peak_hour(f.metrics.peak_hour)}
        """
      end)
      |> Enum.join("\n")

    totals_text =
      """
      Totales Consolidados JSON:
        - Usuarios totales (suma): #{totals.total_users}
        - Activos (suma): #{totals.active_users}
        - Inactivos (suma): #{totals.inactive_users}
      """

    """
    --------------------------------------------------------------------------------
    MÉTRICAS DE ARCHIVOS JSON
    --------------------------------------------------------------------------------
    #{if per_file == "", do: "No JSON files processed.\n", else: per_file}
    #{totals_text}
    """
  end

  # Builds the LOG metrics section, including per-file metrics
  # and consolidated totals.
  defp build_log(files, totals) do
    per_file =
      files
      |> Enum.map(fn f ->
        """
        [Archivo: #{Path.basename(f.path)}]
          * Total de entradas: #{f.metrics.total_entries}
          * Distribución por nivel: #{format_map(f.metrics.by_level)}
          * Componentes con más errores: #{format_top(f.metrics.top_error_component, "errores")}
          * Distribución temporal (por hora): #{format_map(f.metrics.by_hour)}
          * Errores más frecuentes:
        #{format_top_errors(f.metrics.top_error_messages)}
          * Tiempo entre errores críticos (seg): #{format_gaps(f.metrics.critical_error_gaps_seconds)}
          * Patrones de error recurrentes:
        #{format_patterns(f.metrics.recurrent_error_patterns)}
        """
      end)
      |> Enum.join("\n")

    totals_text =
      """
      Totales Consolidados LOG:
        - Entradas totales: #{totals.total_entries}
        - Distribución por nivel: #{format_map(totals.by_level)}
      """

    """
    --------------------------------------------------------------------------------
    MÉTRICAS DE ARCHIVOS LOG
    --------------------------------------------------------------------------------
    #{if per_file == "", do: "No LOG files processed.\n", else: per_file}
    #{totals_text}
    """
  end

  # Builds the error section of the report.
  # Errors are already normalized into printable strings.
  defp build_errors(errors) do
    body =
      errors
      |> Enum.map(fn e -> "✗ #{e.path}: #{e.error}" end)
      |> Enum.join("\n")

    """
    --------------------------------------------------------------------------------
    ERRORES Y ADVERTENCIAS
    --------------------------------------------------------------------------------
    #{if body == "", do: "Sin errores globales.\n", else: body <> "\n"}
    """
  end

  # Static footer section
  defp footer do
    """
    ================================================================================
                               FIN DEL REPORTE
    ================================================================================
    """
  end

  # Formats elapsed seconds with fixed precision
  defp format_seconds(v), do: Float.round(v, 4)

  # Formats a date range
  defp format_range({nil, nil}), do: "N/A"
  defp format_range({min, max}), do: "#{min} a #{max}"

  # Formats a "top" metric with units
  defp format_top(nil, _unit), do: "N/A"
  defp format_top(%{name: n, value: v}, unit), do: "#{n} (#{v} #{unit})"

  # Formats a monetary top metric
  defp format_top_money(nil), do: "N/A"
  defp format_top_money(%{name: n, value: v}), do: "#{n} ($#{Float.round(v, 2)})"

  # Formats a list of actions
  defp format_actions([]), do: "    (sin acciones)\n"

  defp format_actions(list) do
    list
    |> Enum.with_index(1)
    |> Enum.map(fn {%{action: a, count: c}, idx} ->
      "    #{idx}. #{a} (#{c} veces)\n"
    end)
    |> Enum.join()
  end

  # Formats peak hour metric
  defp format_peak_hour(nil), do: "N/A"
  defp format_peak_hour(%{hour: h, sessions: c}), do: "#{h}:00 (#{c} sesiones)"

  # Formats generic maps (used for levels, hours, etc.)
  defp format_map(map) when map == %{}, do: "N/A"

  defp format_map(map) do
    map
    |> Enum.sort_by(fn {k, _v} -> k end)
    |> Enum.map(fn {k, v} -> "#{k}=#{v}" end)
    |> Enum.join(", ")
  end

  # Formats top error messages
  defp format_top_errors([]), do: "    (sin errores críticos)\n"

  defp format_top_errors(list) do
    list
    |> Enum.with_index(1)
    |> Enum.map(fn {%{message: m, count: c}, idx} ->
      "    #{idx}. #{m} (#{c})\n"
    end)
    |> Enum.join()
  end

  # Formats recurrent error patterns
  defp format_patterns([]), do: "    (sin errores críticos)\n"

  defp format_patterns(list) do
    list
    |> Enum.with_index(1)
    |> Enum.map(fn {%{pattern: p, count: c}, idx} ->
      "    #{idx}. #{p} (#{c})\n"
    end)
    |> Enum.join()
  end

  # Formats critical error gap statistics
  defp format_gaps(%{count: 0}), do: "N/A"

  defp format_gaps(g),
    do: "avg=#{Float.round(g.avg, 2)}, min=#{g.min}, max=#{g.max}, n=#{g.count}"
end
