defmodule API.FileProcessor.ReportGenerator do
  # Builds the complete report content as a single string.
  # Receives a fully-structured report_data map generated by FileProcessor.
  def build(report_data) do
    # Capture the current UTC timestamp truncated to seconds
    now = NaiveDateTime.utc_now() |> NaiveDateTime.truncate(:second)

    # Build the report header section
    header = """
    ================================================================================
                        FILE PROCESSING REPORT
    ================================================================================
    Generation date: #{now}
    Single directory: #{report_data.directory || "N/A"}
    Processing mode: #{report_data.mode}
    """

    # Build each major section of the report independently
    summary = build_summary(report_data)

    csv_section = build_csv(report_data.csv_files, report_data.csv_totals)
    json_section = build_json(report_data.json_files, report_data.json_totals)
    log_section = build_log(report_data.log_files, report_data.log_totals)

    errors_section = build_errors(report_data.errors)

    # Concatenate only non-empty optional sections
    optional_sections =
      [csv_section, json_section, log_section]
      |> Enum.reject(&(&1 == ""))

    [header, summary]
    |> Kernel.++(optional_sections)
    |> Kernel.++([errors_section, footer()])
    |> Enum.join("\n")
  end

  # Writes the report content to disk and returns the absolute path.
  # Raises an exception if the write fails (intentional, fail-fast behavior).
  def write!(path, content) do
    File.write!(path, content)
    Path.expand(path)
  end

  # Builds the executive summary section of the report.
  defp build_summary(d) do
    # Extract basic counters
    total = d.counts.total
    ok = d.counts.ok
    failed = d.counts.failed

    # Avoid division by zero
    success_rate =
      if total == 0 do
        0.0
      else
        ok * 100.0 / total
      end

    """
    --------------------------------------------------------------------------------
    EXECUTIVE SUMMARY
    --------------------------------------------------------------------------------
    Total files processed: #{total}
      - CSV files: #{d.counts.csv}
      - JSON files: #{d.counts.json}
      - LOG files: #{d.counts.log}

    Total processing time: #{format_seconds(d.elapsed_seconds)} seconds
    Files with errors: #{failed}
    Success rate: #{Float.round(success_rate, 1)}%
    """
  end

  # Builds the CSV metrics section, including per-file metrics
  # and consolidated totals.
  #
  # Rules:
  # - If there are no CSV files at all, return "" so the section is omitted.
  # - Only include per-file metrics for status == :ok.
  # - Files with :partial or :failed are listed as omitted with a short message.
  defp build_csv([], _totals), do: ""

  defp build_csv(files, totals) do
    ok_files = Enum.filter(files, &(&1.status == :ok))
    bad_files = Enum.reject(files, &(&1.status == :ok))

    per_file =
      ok_files
      |> Enum.map(fn f ->
        """
        [File: #{Path.basename(f.path)}]
          * Total sales: $#{Float.round(f.metrics.total_sales, 2)}
          * Unique products: #{f.metrics.unique_products}
          * Best-selling product: #{format_top(f.metrics.top_product, "units")}
          * Highest-revenue category: #{format_top_money(f.metrics.top_category)}
          * Average discount applied: #{Float.round(f.metrics.avg_discount_pct, 2)}%
          * Period: #{format_range(f.metrics.date_range)}
        """
      end)
      |> Enum.join("\n")

    omitted = format_omitted_files(bad_files)

    totals_text =
      cond do
        ok_files == [] ->
          "Consolidated CSV totals: N/A (no CSV files with :ok status)\n"

        true ->
          """
          Consolidated CSV totals:
            - Total sales: $#{Float.round(totals.total_sales, 2)}
            - Total unique products: #{totals.unique_products}
          """
      end

    """
    --------------------------------------------------------------------------------
    CSV FILE METRICS
    --------------------------------------------------------------------------------
    #{if per_file == "", do: "No CSV metrics were generated (no files with :ok status).\n", else: per_file}
    #{omitted}
    #{totals_text}
    """
  end

  # Builds the JSON metrics section, including per-file metrics
  # and consolidated totals.
  #
  # Rules:
  # - If there are no JSON files at all, return "" so the section is omitted.
  # - Only include per-file metrics for status == :ok.
  # - Files with :partial or :failed are listed as omitted with a short message.
  defp build_json([], _totals), do: ""

  defp build_json(files, totals) do
    ok_files = Enum.filter(files, &(&1.status == :ok))
    bad_files = Enum.reject(files, &(&1.status == :ok))

    per_file =
      ok_files
      |> Enum.map(fn f ->
        """
        [File: #{Path.basename(f.path)}]
          * Registered users: #{f.metrics.total_users}
          * Active users: #{f.metrics.active_users}
          * Inactive users: #{f.metrics.inactive_users}
          * Average session duration: #{Float.round(f.metrics.avg_session_seconds / 60.0, 2)} minutes
          * Total pages visited: #{f.metrics.total_pages}
          * Top actions:
        #{format_actions(f.metrics.top_actions)}
          * Peak activity hour: #{format_peak_hour(f.metrics.peak_hour)}
        """
      end)
      |> Enum.join("\n")

    omitted = format_omitted_files(bad_files)

    totals_text =
      cond do
        ok_files == [] ->
          "Consolidated JSON totals: N/A (no JSON files with :ok status)\n"

        true ->
          """
          Consolidated JSON totals:
            - Total users (sum): #{totals.total_users}
            - Active (sum): #{totals.active_users}
            - Inactive (sum): #{totals.inactive_users}
          """
      end

    """
    --------------------------------------------------------------------------------
    JSON FILE METRICS
    --------------------------------------------------------------------------------
    #{if per_file == "", do: "No JSON metrics were generated (no files with :ok status).\n", else: per_file}
    #{omitted}
    #{totals_text}
    """
  end

  # Builds the LOG metrics section, including per-file metrics
  # and consolidated totals.
  #
  # Rules:
  # - If there are no LOG files at all, return "" so the section is omitted.
  # - Only include per-file metrics for status == :ok.
  # - Files with :partial or :failed are listed as omitted with a short message.
  defp build_log([], _totals), do: ""

  defp build_log(files, totals) do
    ok_files = Enum.filter(files, &(&1.status == :ok))
    bad_files = Enum.reject(files, &(&1.status == :ok))

    per_file =
      ok_files
      |> Enum.map(fn f ->
        """
        [File: #{Path.basename(f.path)}]
          * Total entries: #{f.metrics.total_entries}
          * Level distribution: #{format_map(f.metrics.by_level)}
          * Components with most errors: #{format_top(f.metrics.top_error_component, "errors")}
          * Time distribution (by hour): #{format_map(f.metrics.by_hour)}
          * Most frequent errors:
        #{format_top_errors(f.metrics.top_error_messages)}
          * Time between critical errors (sec): #{format_gaps(f.metrics.critical_error_gaps_seconds)}
          * Recurring error patterns:
        #{format_patterns(f.metrics.recurrent_error_patterns)}
        """
      end)
      |> Enum.join("\n")

    omitted = format_omitted_files(bad_files)

    totals_text =
      cond do
        ok_files == [] ->
          "Consolidated LOG totals: N/A (no LOG files with :ok status)\n"

        true ->
          """
          Consolidated LOG totals:
            - Total entries: #{totals.total_entries}
            - Level distribution: #{format_map(totals.by_level)}
          """
      end

    """
    --------------------------------------------------------------------------------
    LOG FILE METRICS
    --------------------------------------------------------------------------------
    #{if per_file == "", do: "No LOG metrics were generated (no files with :ok status).\n", else: per_file}
    #{omitted}
    #{totals_text}
    """
  end

  # Builds the error section of the report.
  # Errors are already normalized into printable strings.
  defp build_errors(errors) do
    body =
      errors
      |> Enum.map(fn e -> "âœ— #{e.path}: #{e.error}" end)
      |> Enum.join("\n")

    """
    --------------------------------------------------------------------------------
    ERRORS AND WARNINGS
    --------------------------------------------------------------------------------
    #{if body == "", do: "No global errors.\n", else: body <> "\n"}
    """
  end

  # Formats a short list of files omitted from metrics due to non-ok status
  defp format_omitted_files([]), do: ""

  defp format_omitted_files(files) do
    items =
      files
      |> Enum.map(fn f ->
        msg = first_error_message(f)
        "  - #{Path.basename(f.path)} (#{f.status}): #{msg}"
      end)
      |> Enum.join("\n")

    """
    Omitted files (errors were found):
    #{items}
    """
  end

  # Tries to extract a short error message from the file item itself
  defp first_error_message(%{errors: [first | _]}) when is_map(first) do
    line = Map.get(first, :line)
    msg = Map.get(first, :error, inspect(first))

    if is_integer(line) do
      "line #{line}: #{msg}"
    else
      msg
    end
  end

  defp first_error_message(_), do: "See the errors section for more details"

  # Static footer section
  defp footer do
    """
    ================================================================================
                               END OF REPORT
    ================================================================================
    """
  end

  # Formats elapsed seconds with fixed precision
  defp format_seconds(v), do: Float.round(v, 4)

  # Formats a date range
  defp format_range({nil, nil}), do: "N/A"
  defp format_range({min, max}), do: "#{min} to #{max}"

  # Formats a "top" metric with units
  defp format_top(nil, _unit), do: "N/A"
  defp format_top(%{name: n, value: v}, unit), do: "#{n} (#{v} #{unit})"

  # Formats a monetary top metric
  defp format_top_money(nil), do: "N/A"
  defp format_top_money(%{name: n, value: v}), do: "#{n} ($#{Float.round(v, 2)})"

  # Formats a list of actions
  defp format_actions([]), do: "    (no actions)\n"

  defp format_actions(list) do
    list
    |> Enum.with_index(1)
    |> Enum.map(fn {%{action: a, count: c}, idx} ->
      "    #{idx}. #{a} (#{c} times)\n"
    end)
    |> Enum.join()
  end

  # Formats peak hour metric
  defp format_peak_hour(nil), do: "N/A"
  defp format_peak_hour(%{hour: h, sessions: c}), do: "#{h}:00 (#{c} sessions)"

  # Formats generic maps (used for levels, hours, etc.)
  defp format_map(map) when map == %{}, do: "N/A"

  defp format_map(map) do
    map
    |> Enum.sort_by(fn {k, _v} -> k end)
    |> Enum.map(fn {k, v} -> "#{k}=#{v}" end)
    |> Enum.join(", ")
  end

  # Formats top error messages
  defp format_top_errors([]), do: "    (no critical errors)\n"

  defp format_top_errors(list) do
    list
    |> Enum.with_index(1)
    |> Enum.map(fn {%{message: m, count: c}, idx} ->
      "    #{idx}. #{m} (#{c})\n"
    end)
    |> Enum.join()
  end

  # Formats recurrent error patterns
  defp format_patterns([]), do: "    (no critical errors)\n"

  defp format_patterns(list) do
    list
    |> Enum.with_index(1)
    |> Enum.map(fn {%{pattern: p, count: c}, idx} ->
      "    #{idx}. #{p} (#{c})\n"
    end)
    |> Enum.join()
  end

  # Formats critical error gap statistics
  defp format_gaps(%{count: 0}), do: "N/A"

  defp format_gaps(g),
    do: "avg=#{Float.round(g.avg, 2)}, min=#{g.min}, max=#{g.max}, n=#{g.count}"
end
